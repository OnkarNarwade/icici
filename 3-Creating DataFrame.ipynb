{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a33f53f-acbf-4cc9-af95-26e2c70538fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DataFrame\n",
    "\n",
    "* Creates a `DataFrame` from an `RDD`, a `list`, a `pandas.DataFrame`, a `numpy.ndarray`, or a `pyarrow.Table`.\n",
    "\n",
    "### There are **4 different ways** to create a `DataFrame` in **PySpark**\n",
    "1. Create a DataFrame from a list of tuples.\n",
    "2. Create a DataFrame from a list of dictionaries.\n",
    "3. Create a DataFrame from Row objects.\n",
    "4. Create a DataFrame from a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6a2e73-ae36-42b9-a8e1-b2386a12f96d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Creating DataFrame\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1b36340-9213-4df9-b553-2c42abf47f58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Create a DataFrame from a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "628348ab-8256-4e13-b35c-f01966756c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------+---------+\n| id|  name|age|salary|  country|\n+---+------+---+------+---------+\n|  1|name 1| 24|150000|    India|\n|  2|name 2| 25|160000|      USA|\n|  3|name 3| 26|170000|   Canada|\n|  4|name 4| 27|180000|       UK|\n|  5|name 5| 28|190000|Australia|\n+---+------+---+------+---------+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- age: long (nullable = true)\n |-- salary: long (nullable = true)\n |-- country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  (1, 'name 1', 24, 150000, 'India'),\n",
    "  (2, 'name 2', 25, 160000, 'USA'),\n",
    "  (3, 'name 3', 26, 170000, 'Canada'),\n",
    "  (4, 'name 4', 27, 180000, 'UK'),\n",
    "  (5, 'name 5', 28, 190000, 'Australia')\n",
    "]\n",
    "\n",
    "# Also use StructType to define DataType\n",
    "schema = '''\n",
    "  id int,\n",
    "  name string,\n",
    "  age int,\n",
    "  salary double,\n",
    "  country string\n",
    "'''\n",
    "\n",
    "columns = ['id', 'name', 'age', 'salary', 'country']\n",
    "\n",
    "df = spark.createDataFrame(data, columns)  # Pass Schema if you want to change Datatype else Default\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c01f2f-fbf3-4d5b-8b7c-ad65354fab83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyspark.sql.connect.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "780205fa-3ee9-49f1-a030-296d1ba82c39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Create a DataFrame from a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "172ec30e-b1ea-4e7c-ad46-e92ecaffc14f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+--------+---------+\n| id|  name|age|  salary|  country|\n+---+------+---+--------+---------+\n|  1|name 1| 24|150000.0|    India|\n|  2|name 2| 25|160000.0|      USA|\n|  3|name 3| 26|170000.0|   Canada|\n|  4|name 4| 27|180000.0|       UK|\n|  5|name 5| 28|190000.0|Australia|\n+---+------+---+--------+---------+\n\nroot\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: double (nullable = true)\n |-- country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  {'id': 1, 'name': 'name 1', 'age': 24, 'salary': 150000, 'country': 'India'},\n",
    "  {'id': 2, 'name': 'name 2', 'age': 25, 'salary': 160000, 'country': 'USA'},\n",
    "  {'id': 3, 'name': 'name 3', 'age': 26, 'salary': 170000, 'country': 'Canada'},\n",
    "  {'id': 4, 'name': 'name 4', 'age': 27, 'salary': 180000, 'country': 'UK'},\n",
    "  {'id': 5, 'name': 'name 5', 'age': 28, 'salary': 190000, 'country': 'Australia'}\n",
    "]\n",
    "\n",
    "schema = '''\n",
    "  id int,\n",
    "  name string,\n",
    "  age int,\n",
    "  salary double,\n",
    "  country string\n",
    "'''\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d8708a-014c-4cf7-af5d-16669ed6bd87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Create a DataFrame from Row objects.\n",
    "\n",
    "### **Row()**\n",
    "* A row in `DataFrame`.\n",
    "* Row can be used to create a row object by using named arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76ad5b09-78ae-4d6b-b9bf-dda29324a129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+--------+---------+\n| id|  name|age|  salary|  country|\n+---+------+---+--------+---------+\n|  1|name 1| 24|150000.0|    India|\n|  2|name 2| 25|160000.0|      USA|\n|  3|name 3| 26|170000.0|   Canada|\n|  4|name 4| 27|180000.0|       UK|\n|  5|name 5| 28|190000.0|Australia|\n+---+------+---+--------+---------+\n\nroot\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: double (nullable = true)\n |-- country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "data = [\n",
    "  Row(id=1, name='name 1', age=24, salary=150000, country='India'),\n",
    "  Row(id=2, name='name 2', age=25, salary=160000, country='USA'),\n",
    "  Row(id=3, name='name 3', age=26, salary=170000, country='Canada'),\n",
    "  Row(id=4, name='name 4', age=27, salary=180000, country='UK'),\n",
    "  Row(id=5, name='name 5', age=28, salary=190000, country='Australia')\n",
    "]\n",
    "\n",
    "# Another way\n",
    "Employee = Row('id', 'name', 'age', 'salary', 'country')\n",
    "\n",
    "data2 = [\n",
    "    Employee(1, 'name 1', 24, 150000, 'India'),\n",
    "    Employee(2, 'name 2', 25, 160000, 'USA'),\n",
    "    Employee(3, 'name 3', 26, 170000, 'Canada'),\n",
    "    Employee(4, 'name 4', 27, 180000, 'UK'),\n",
    "    Employee(5, 'name 5', 28, 190000, 'Australia'),\n",
    "]\n",
    "\n",
    "schema = '''\n",
    "  id int,\n",
    "  name string,\n",
    "  age int,\n",
    "  salary double,\n",
    "  country string\n",
    "'''\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed18bca6-c3c9-4b8a-bd2d-5fdc14351b10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Create a DataFrame from a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81df567b-3e67-40a8-8df2-a34c277322c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------+---------+\n| id|  name|age|salary|  country|\n+---+------+---+------+---------+\n|  1|name 1| 24|150000|    India|\n|  2|name 2| 25|160000|      USA|\n|  3|name 3| 26|170000|   Canada|\n|  4|name 4| 27|180000|       UK|\n|  5|name 5| 28|190000|Australia|\n+---+------+---+------+---------+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- age: long (nullable = true)\n |-- salary: long (nullable = true)\n |-- country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "  'id': [1, 2, 3, 4, 5],\n",
    "  'name': ['name 1', 'name 2', 'name 3', 'name 4', 'name 5'],\n",
    "  'age': [24, 25, 26, 27, 28],\n",
    "  'salary': [150000, 160000, 170000, 180000, 190000],\n",
    "  'country': ['India', 'USA', 'Canada', 'UK', 'Australia']\n",
    "}\n",
    "\n",
    "pdf = pd.DataFrame(data)\n",
    "\n",
    "schema = '''\n",
    "  id int,\n",
    "  name string,\n",
    "  age int,\n",
    "  salary double,\n",
    "  country string\n",
    "'''\n",
    "\n",
    "df = spark.createDataFrame(pdf)  # Pass schema if needed\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea898001-7907-4ac5-978f-ac4f811c947f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3-Creating DataFrame",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}